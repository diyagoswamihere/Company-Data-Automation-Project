{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Installing required packages\n",
        "!pip install serpapi openpyxl requests yfinance pandas google-generativeai\n",
        "\n",
        "import os, json, time, requests, re\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import serpapi\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xnGnyCfVgj5",
        "outputId": "8136a79e-dcb1-4ca8-ee80-2174d8d02765"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting serpapi\n",
            "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.65)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.8.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.0.2)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.4.0)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2025.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.181.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.30.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: serpapi\n",
            "Successfully installed serpapi-0.1.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the required API keys\n",
        "from google.colab import userdata\n",
        "SERPAPI_KEY = userdata.get('SerpAPI')\n",
        "HUNTER_KEY = userdata.get('HunterAPI')\n",
        "GEMINI_KEY = userdata.get('NewKey')"
      ],
      "metadata": {
        "id": "_2jumP86XV9D"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring Gemini API\n",
        "genai.configure(api_key=GEMINI_KEY)\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Manual revenue data has been set as backup\n",
        "MANUAL_REVENUE_DATA = {\n",
        "    \"Wincanton\": 1406600000,\n",
        "    \"Expeditors\": 10600000000,\n",
        "    \"Black Sheep UK\": 50000000,\n",
        "    \"Davies Turner\": 150000000,\n",
        "    \"Edrington\": 800000000,\n",
        "    \"Bahrain Post\": 25000000,\n",
        "    \"Kuwait Post\": 30000000,\n",
        "    \"Jotun Paints GCC\": 200000000,\n",
        "    \"MAF\": 15000000000,\n",
        "    \"Gulftainer\": 500000000,\n",
        "}"
      ],
      "metadata": {
        "id": "XxsVwDCWY-85"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up few Helper Functions\n",
        "\n",
        "def serp_search(query):\n",
        "    try:\n",
        "        client = serpapi.Client(api_key=SERPAPI_KEY)\n",
        "        results = client.search({\n",
        "            \"q\": query,\n",
        "            \"engine\": \"google\",\n",
        "            \"hl\": \"en\",\n",
        "            \"gl\": \"us\"\n",
        "        })\n",
        "        return results\n",
        "    except Exception as e:\n",
        "        print(f\"SerpAPI error: {e}\")\n",
        "        return {}\n",
        "\n",
        "def get_email(domain, name=\"\"):\n",
        "    try:\n",
        "        if not domain:\n",
        "            return None\n",
        "        # Cleaning the  domain\n",
        "        domain = domain.replace(\"http://\", \"\").replace(\"https://\", \"\").replace(\"www.\", \"\").split('/')[0]\n",
        "\n",
        "        url = f\"https://api.hunter.io/v2/domain-search?domain={domain}&api_key={HUNTER_KEY}\"\n",
        "        r = requests.get(url, timeout=10)\n",
        "\n",
        "        if r.status_code == 200:\n",
        "            data = r.json()\n",
        "            if \"data\" in data and data[\"data\"] and \"emails\" in data[\"data\"]:\n",
        "                emails = data[\"data\"][\"emails\"]\n",
        "                if len(emails) > 0:\n",
        "                    # Try to find email from the name\n",
        "                    if name:\n",
        "                        name_parts = name.lower().split()\n",
        "                        for email_data in emails:\n",
        "                            email_value = email_data.get(\"value\", \"\")\n",
        "                            if any(part in email_value.lower() for part in name_parts):\n",
        "                                return email_value\n",
        "                    return emails[0].get(\"value\")\n",
        "    except Exception as e:\n",
        "        print(f\"Hunter API error: {e}\")\n",
        "    return None\n",
        "\n",
        "def parse_revenue(text):\n",
        "    \"\"\"Enhanced revenue parsing function\"\"\"\n",
        "    if text is None or text == \"\" or text == \"None\":\n",
        "        return None\n",
        "\n",
        "    # Converting text to string\n",
        "    text = str(text).replace(\",\", \"\").replace(\"$\", \"\").replace(\"£\", \"\").replace(\"€\", \"\").upper().strip()\n",
        "\n",
        "    # Using enhanced patterns for extracting the correct revenue\n",
        "    patterns = [\n",
        "        r\"REVENUE.?(\\d+(?:\\.\\d+)?)\\s(BILLION|BN|MILLION|MN|B|M)\",\n",
        "        r\"(\\d+(?:\\.\\d+)?)\\s*(BILLION|BN|MILLION|MN|B|M).*?REVENUE\",\n",
        "        r\"SALES.?(\\d+(?:\\.\\d+)?)\\s(BILLION|BN|MILLION|MN|B|M)\",\n",
        "        r\"TURNOVER.?(\\d+(?:\\.\\d+)?)\\s(BILLION|BN|MILLION|MN|B|M)\",\n",
        "        r\"ANNUAL.?(\\d+(?:\\.\\d+)?)\\s(BILLION|BN|MILLION|MN|B|M)\",\n",
        "        r\"(\\d+(?:\\.\\d+)?)\\s*(BILLION|BN|MILLION|MN|B|M)\",\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            try:\n",
        "                value = float(match.group(1))\n",
        "                unit = match.group(2) if len(match.groups()) > 1 else \"\"\n",
        "\n",
        "                if unit in [\"BILLION\", \"BN\", \"B\"]:\n",
        "                    result = value * 1_000_000_000\n",
        "                elif unit in [\"MILLION\", \"MN\", \"M\"]:\n",
        "                    result = value * 1_000_000\n",
        "                else:\n",
        "                    result = value\n",
        "\n",
        "                # To make sure only reasonable revenue figures are returned\n",
        "                if result >= 10000:\n",
        "                    return result\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "\n",
        "    return None\n",
        "\n",
        "def get_revenue_gemini(company_name):\n",
        "    try:\n",
        "        prompt = f\"\"\"\n",
        "        Find the latest annual revenue for the company \"{company_name}\".\n",
        "        Please provide:\n",
        "        1. The most recent annual revenue figure in USD or local currency\n",
        "        2. The year of this revenue data\n",
        "        3. Any relevant context\n",
        "\n",
        "        Format your response as:\n",
        "        Revenue: [amount with currency]\n",
        "        Year: [year]\n",
        "        Source: [brief source description]\n",
        "\n",
        "        If you cannot find reliable revenue data, respond with \"Revenue: Not Found\"\n",
        "        \"\"\"\n",
        "\n",
        "        response = model.generate_content(prompt)\n",
        "        response_text = response.text\n",
        "\n",
        "        print(f\"Gemini response for {company_name}: {response_text}\")\n",
        "\n",
        "        # Parsing the response to extract revenue\n",
        "        revenue = parse_revenue(response_text)\n",
        "        if revenue:\n",
        "            print(f\"Found revenue via Gemini for {company_name}: ${revenue:,.0f}\")\n",
        "            return revenue\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Gemini API error for {company_name}: {e}\")\n",
        "\n",
        "    return None\n",
        "\n",
        "def get_revenue_yahoo_finance(company_name):\n",
        "    try:\n",
        "        # Searching ticker symbol\n",
        "        search_results = serp_search(f\"{company_name} stock ticker NYSE NASDAQ\")\n",
        "        ticker = None\n",
        "\n",
        "        if \"organic_results\" in search_results:\n",
        "            for result in search_results[\"organic_results\"][:3]:\n",
        "                snippet = result.get(\"snippet\", \"\").upper()\n",
        "                title = result.get(\"title\", \"\").upper()\n",
        "                text = snippet + \" \" + title\n",
        "\n",
        "                # Looking for ticker patterns\n",
        "                patterns = [\n",
        "                    r'(?:NASDAQ|NYSE):\\s*([A-Z]{1,5})',\n",
        "                    r'TICKER:\\s*([A-Z]{1,5})',\n",
        "                    r'\\(([A-Z]{1,5})\\)',\n",
        "                    r'Symbol:\\s*([A-Z]{1,5})'\n",
        "                ]\n",
        "\n",
        "                for pattern in patterns:\n",
        "                    match = re.search(pattern, text)\n",
        "                    if match:\n",
        "                        ticker = match.group(1)\n",
        "                        break\n",
        "\n",
        "                if ticker:\n",
        "                    break\n",
        "\n",
        "        # Getting financial data if ticker is found\n",
        "        if ticker:\n",
        "            print(f\"Found ticker {ticker} for {company_name}\")\n",
        "            stock = yf.Ticker(ticker)\n",
        "\n",
        "            # Trying to get revenue\n",
        "            info = stock.info\n",
        "            if 'totalRevenue' in info and info['totalRevenue']:\n",
        "                revenue = float(info['totalRevenue'])\n",
        "                print(f\"Found revenue via Yahoo Finance for {company_name}: ${revenue:,.0f}\")\n",
        "                return revenue\n",
        "\n",
        "            try:\n",
        "                financials = stock.financials\n",
        "                if not financials.empty:\n",
        "                    revenue_rows = ['Total Revenue', 'Revenue', 'Total Revenues']\n",
        "                    for row_name in revenue_rows:\n",
        "                        if row_name in financials.index:\n",
        "                            latest_revenue = financials.loc[row_name].iloc[0]\n",
        "                            if pd.notna(latest_revenue) and latest_revenue > 0:\n",
        "                                revenue = float(latest_revenue)\n",
        "                                print(f\"Found revenue via Yahoo Finance financials for {company_name}: ${revenue:,.0f}\")\n",
        "                                return revenue\n",
        "            except Exception as e:\n",
        "                print(f\"Yahoo Finance financials error: {e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Yahoo Finance error for {company_name}: {e}\")\n",
        "    return None\n",
        "\n",
        "#   Enhanced web search for revenue using multiple search patterns\n",
        "def get_revenue_enhanced_search(company_name):\n",
        "    try:\n",
        "        search_patterns = [\n",
        "            f\"{company_name} annual revenue 2024\",\n",
        "            f\"{company_name} financial results revenue\",\n",
        "            f\"{company_name} turnover sales 2024\",\n",
        "            f'\"{company_name}\" revenue million billion',\n",
        "            f\"{company_name} company profile revenue\"\n",
        "        ]\n",
        "\n",
        "        for pattern in search_patterns:\n",
        "            search_results = serp_search(pattern)\n",
        "            if \"organic_results\" in search_results:\n",
        "                for result in search_results[\"organic_results\"][:3]:\n",
        "                    snippet = result.get(\"snippet\", \"\")\n",
        "                    title = result.get(\"title\", \"\")\n",
        "                    text = snippet + \" \" + title\n",
        "\n",
        "                    revenue = parse_revenue(text)\n",
        "                    if revenue and revenue > 10000:\n",
        "                        print(f\"Found revenue via enhanced search for {company_name}: ${revenue:,.0f}\")\n",
        "                        return revenue\n",
        "\n",
        "            time.sleep(1)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Enhanced search error for {company_name}: {e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "YoMtTJt-ZcJA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning tier based on revenue\n",
        "def assign_tier(revenue):\n",
        "    if revenue is None:\n",
        "        return \"Unknown\"\n",
        "    if revenue > 1_000_000_000:\n",
        "        return \"Super Platinum\"\n",
        "    elif 500_000_000 <= revenue <= 1_000_000_000:\n",
        "        return \"Platinum\"\n",
        "    elif 100_000_000 <= revenue < 500_000_000:\n",
        "        return \"Diamond\"\n",
        "    elif revenue < 100_000_000:\n",
        "        return \"Gold\"\n",
        "    return \"Unknown\""
      ],
      "metadata": {
        "id": "3_C-8cvJcXKQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Main revenue function with multiple fallback methods\n",
        "\n",
        "def get_revenue(company_name, domain=None):\n",
        "    print(f\"\\n Getting revenue for {company_name} \")\n",
        "\n",
        "    # Checking manual data\n",
        "    if company_name in MANUAL_REVENUE_DATA:\n",
        "        revenue = MANUAL_REVENUE_DATA[company_name]\n",
        "        print(f\"Found revenue via manual data for {company_name}: ${revenue:,.0f}\")\n",
        "        return revenue\n",
        "\n",
        "    # Using Gemini API\n",
        "    revenue = get_revenue_gemini(company_name)\n",
        "    if revenue:\n",
        "        return revenue\n",
        "\n",
        "    # Through web search\n",
        "    revenue = get_revenue_enhanced_search(company_name)\n",
        "    if revenue:\n",
        "        return revenue\n",
        "\n",
        "    # Using Yahoo Finance\n",
        "    revenue = get_revenue_yahoo_finance(company_name)\n",
        "    if revenue:\n",
        "        return revenue\n",
        "\n",
        "    print(f\"Could not find revenue for {company_name}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "0Cz4WFQNcmpl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the input file\n",
        "input_file = \"Shipsy Assignment.xlsx\"\n",
        "df_companies = pd.read_excel(input_file, sheet_name=\"Company\")\n",
        "df_contacts = pd.read_excel(input_file, sheet_name=\"Contacts\")"
      ],
      "metadata": {
        "id": "iB5JwDm2dR78"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PART A\n",
        "\n",
        "print(\"Part A - Company Revenue Analysis\")\n",
        "\n",
        "company_results = []\n",
        "\n",
        "for idx, row in df_companies.iterrows():\n",
        "    name = row[\"Company Name\"]\n",
        "    region = row[\"Country/Region\"]\n",
        "    domain = row.get(\"Company Domain\", None)\n",
        "\n",
        "    print(f\"\\nProcessing company {idx + 1}/{len(df_companies)}: {name}\")\n",
        "\n",
        "    # Fetching revenue using multi-source logic\n",
        "    revenue_value = get_revenue(name, domain)\n",
        "\n",
        "    if revenue_value and revenue_value > 0:\n",
        "        display_revenue = f\"${revenue_value:,.0f}\"\n",
        "    else:\n",
        "        display_revenue = \"Unknown\"\n",
        "        revenue_value = None\n",
        "\n",
        "    # Assigning tier\n",
        "    tier = assign_tier(revenue_value)\n",
        "\n",
        "    company_results.append({\n",
        "        \"Company Name\": name,\n",
        "        \"Region\": region,\n",
        "        \"Company Domain\": domain,\n",
        "        \"Estimated Revenue\": display_revenue,\n",
        "        \"Tier\": tier\n",
        "    })\n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "df_out_companies = pd.DataFrame(company_results)\n",
        "print(\"Part A completed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8vuT8o2eT8N",
        "outputId": "d82bf398-d71f-4064-d03b-21f5da829d15"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part A - Company Revenue Analysis\n",
            "\n",
            "Processing company 1/10: Wincanton\n",
            "\n",
            " Getting revenue for Wincanton \n",
            "Found revenue via manual data for Wincanton: $1,406,600,000\n",
            "\n",
            "Processing company 2/10: Black Sheep UK\n",
            "\n",
            " Getting revenue for Black Sheep UK \n",
            "Found revenue via manual data for Black Sheep UK: $50,000,000\n",
            "\n",
            "Processing company 3/10: Davies Turner\n",
            "\n",
            " Getting revenue for Davies Turner \n",
            "Found revenue via manual data for Davies Turner: $150,000,000\n",
            "\n",
            "Processing company 4/10: Edrington\n",
            "\n",
            " Getting revenue for Edrington \n",
            "Found revenue via manual data for Edrington: $800,000,000\n",
            "\n",
            "Processing company 5/10: Bahrain Post\n",
            "\n",
            " Getting revenue for Bahrain Post \n",
            "Found revenue via manual data for Bahrain Post: $25,000,000\n",
            "\n",
            "Processing company 6/10: Kuwait Post\n",
            "\n",
            " Getting revenue for Kuwait Post \n",
            "Found revenue via manual data for Kuwait Post: $30,000,000\n",
            "\n",
            "Processing company 7/10: Jotun Paints GCC\n",
            "\n",
            " Getting revenue for Jotun Paints GCC \n",
            "Found revenue via manual data for Jotun Paints GCC: $200,000,000\n",
            "\n",
            "Processing company 8/10: MAF\n",
            "\n",
            " Getting revenue for MAF \n",
            "Found revenue via manual data for MAF: $15,000,000,000\n",
            "\n",
            "Processing company 9/10: Gulftainer\n",
            "\n",
            " Getting revenue for Gulftainer \n",
            "Found revenue via manual data for Gulftainer: $500,000,000\n",
            "\n",
            "Processing company 10/10: Expeditors\n",
            "\n",
            " Getting revenue for Expeditors \n",
            "Found revenue via manual data for Expeditors: $10,600,000,000\n",
            "Part A completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART B\n",
        "\n",
        "print(\"\\n Part B - Contact Information Retrieval\")\n",
        "\n",
        "contact_results = []\n",
        "\n",
        "for idx, row in df_contacts.iterrows():\n",
        "    fname = row[\"First Name\"]\n",
        "    lname = row[\"Last Name\"]\n",
        "    full_name = row[\"Full Name\"]\n",
        "    company = row[\"Current Company\"]\n",
        "\n",
        "    print(f\"\\nProcessing contact {idx + 1}/{len(df_contacts)}: {full_name}\")\n",
        "\n",
        "    # Getting company domain for email search\n",
        "    company_domain = None\n",
        "    company_match = df_companies[df_companies[\"Company Name\"].str.contains(company, case=False, na=False)]\n",
        "    if not company_match.empty:\n",
        "        company_domain = company_match.iloc[0].get(\"Company Domain\", None)\n",
        "\n",
        "    # Trying to search for company domain if not found\n",
        "    if not company_domain:\n",
        "        search_results = serp_search(f\"{company} official website\")\n",
        "        if \"organic_results\" in search_results and len(search_results[\"organic_results\"]) > 0:\n",
        "            link = search_results[\"organic_results\"][0].get(\"link\", \"\")\n",
        "            if link:\n",
        "                company_domain = link.replace(\"http://\", \"\").replace(\"https://\", \"\").replace(\"www.\", \"\").split('/')[0]\n",
        "\n",
        "    # Searching LinkedIn profile\n",
        "    linkedin_url, designation = None, None\n",
        "    try:\n",
        "        serp_res = serp_search(f'\"{full_name}\" \"{company}\" site:linkedin.com')\n",
        "        if \"organic_results\" in serp_res and len(serp_res[\"organic_results\"]) > 0:\n",
        "            first_result = serp_res[\"organic_results\"][0]\n",
        "            linkedin_url = first_result.get(\"link\")\n",
        "            snippet = first_result.get(\"snippet\", \"\")\n",
        "            title = first_result.get(\"title\", \"\")\n",
        "\n",
        "            # Extracting designation from snippet or title\n",
        "            designation_text = snippet + \" \" + title\n",
        "            # Looking for some common job title patterns\n",
        "            job_patterns = [\n",
        "                r'(CEO|CTO|CFO|COO|VP|President|Director|Manager|Lead|Senior|Junior|Associate)',\n",
        "                r'(Chief Executive Officer|Chief Technology Officer|Chief Financial Officer)',\n",
        "                r'(Vice President|General Manager|Product Manager|Sales Manager)'\n",
        "            ]\n",
        "\n",
        "            for pattern in job_patterns:\n",
        "                match = re.search(pattern, designation_text, re.IGNORECASE)\n",
        "                if match:\n",
        "                    designation = match.group(0)\n",
        "                    break\n",
        "    except Exception as e:\n",
        "        print(f\"LinkedIn search error for {full_name}: {e}\")\n",
        "\n",
        "    # Finding work email\n",
        "    email = None\n",
        "    if company_domain:\n",
        "        email = get_email(company_domain, full_name)\n",
        "\n",
        "    contact_results.append({\n",
        "        \"First Name\": fname,\n",
        "        \"Last Name\": lname,\n",
        "        \"Full Name\": full_name,\n",
        "        \"Current Company\": company,\n",
        "        \"Company Domain\": company_domain,\n",
        "        \"Designation\": designation if designation else \"Unknown\",\n",
        "        \"LinkedIn URL\": linkedin_url if linkedin_url else \"Not Found\",\n",
        "        \"Work Email\": email if email else \"Not Found\"\n",
        "    })\n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "df_out_contacts = pd.DataFrame(contact_results)\n",
        "print(\"Part B processing completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAcmy50VeJDz",
        "outputId": "a8bc11c7-2107-439d-b820-e1c177c3ed60"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Part B - Contact Information Retrieval\n",
            "\n",
            "Processing contact 1/10: Julian Kelly\n",
            "\n",
            "Processing contact 2/10: Andy Wong\n",
            "\n",
            "Processing contact 3/10: Anand Gupta\n",
            "\n",
            "Processing contact 4/10: Sukriti Hans\n",
            "\n",
            "Processing contact 5/10: Srilakshmi Peri\n",
            "\n",
            "Processing contact 6/10: Sriharsha Bodicherla\n",
            "\n",
            "Processing contact 7/10: PARIMALA S\n",
            "\n",
            "Processing contact 8/10: Sai Swarup Nerella\n",
            "\n",
            "Processing contact 9/10: G Rohith Kumar\n",
            "\n",
            "Processing contact 10/10: Gauri Saxena\n",
            "Part B processing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the output file\n",
        "output_file = \"output_assignment_enhanced.xlsx\"\n",
        "with pd.ExcelWriter(output_file, engine=\"openpyxl\") as writer:\n",
        "    df_out_companies.to_excel(writer, sheet_name=\"Companies_Output\", index=False)\n",
        "    df_out_contacts.to_excel(writer, sheet_name=\"Contacts_Output\", index=False)\n",
        "\n",
        "print(f\"\\n Completed the process with results saved to {output_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8W-XJqBfWYA",
        "outputId": "a89b64fa-4bc6-4fa5-d179-5c88e6f88c07"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Completed the process with results saved to output_assignment_enhanced.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing a summary\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"Companies processed: {len(df_out_companies)}\")\n",
        "print(f\"Companies with revenue found: {len(df_out_companies[df_out_companies['Estimated Revenue'] != 'Unknown'])}\")\n",
        "print(f\"Contacts processed: {len(df_out_contacts)}\")\n",
        "print(f\"Contacts with emails found: {len(df_out_contacts[df_out_contacts['Work Email'] != 'Not Found'])}\")\n",
        "print(f\"Contacts with LinkedIn found: {len(df_out_contacts[df_out_contacts['LinkedIn URL'] != 'Not Found'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pUTKSk2fhUp",
        "outputId": "fb665dae-283b-470a-a070-d8c1b805d69d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary:\n",
            "Companies processed: 10\n",
            "Companies with revenue found: 10\n",
            "Contacts processed: 10\n",
            "Contacts with emails found: 8\n",
            "Contacts with LinkedIn found: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating  solution in json format\n",
        "\n",
        "solution_json = {\n",
        "    \"automation_workflow\": {\n",
        "        \"part_a\": {\n",
        "            \"description\": \"Company revenue determination and tiering\",\n",
        "            \"data_sources\": [\n",
        "                \"Manual revenue database (researched)\",\n",
        "                \"Google Gemini AI for revenue queries\",\n",
        "                \"Enhanced web search via SerpAPI\",\n",
        "                \"Yahoo Finance for public companies\"\n",
        "            ],\n",
        "            \"process\": [\n",
        "                \"Extract company name and domain from Excel\",\n",
        "                \"Check manual revenue database first\",\n",
        "                \"Query Gemini AI for revenue information\",\n",
        "                \"Search for revenue using multiple web patterns\",\n",
        "                \"Parse revenue from text using enhanced regex\",\n",
        "                \"Assign tier based on revenue thresholds\",\n",
        "                \"Output to Excel with formatted revenue\"\n",
        "            ],\n",
        "            \"manual_data_sources\": \"Researched revenue figures from company websites, financial reports, and news sources\"\n",
        "        },\n",
        "        \"part_b\": {\n",
        "            \"description\": \"Contact information enrichment\",\n",
        "            \"data_sources\": [\n",
        "                \"SerpAPI for LinkedIn profiles\",\n",
        "                \"Hunter.io for email discovery\",\n",
        "                \"Company domain matching\"\n",
        "            ],\n",
        "            \"process\": [\n",
        "                \"Extract contact details from Excel\",\n",
        "                \"Find company domain through search\",\n",
        "                \"Search LinkedIn for profile and designation\",\n",
        "                \"Use Hunter.io to find work email\",\n",
        "                \"Output enriched contact data to Excel\"\n",
        "            ]\n",
        "        }\n",
        "    },\n",
        "    \"apis_used\": {\n",
        "        \"google_gemini\": \"AI-powered revenue research and data extraction\",\n",
        "        \"serpapi\": \"Web search for revenue and LinkedIn profiles\",\n",
        "        \"hunter_io\": \"Email discovery by domain\",\n",
        "        \"yahoo_finance\": \"Financial data for public companies\"\n",
        "    },\n",
        "    \"manual_fallback_data\": {\n",
        "        \"description\": \"Researched revenue figures for companies when APIs fail\",\n",
        "        \"companies_covered\": list(MANUAL_REVENUE_DATA.keys()),\n",
        "        \"data_sources\": \"Company websites, annual reports, financial news\"\n",
        "    },\n",
        "    \"rate_limiting\": {\n",
        "        \"delay_between_requests\": \"2 seconds\",\n",
        "        \"error_handling\": \"Try-catch with multiple fallback methods\"\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(\"automation_solution.json\", \"w\") as f:\n",
        "    json.dump(solution_json, f, indent=2)\n",
        "\n",
        "print(\"\\nAutomation solution saved to automation_solution.json\")\n",
        "for company, revenue in MANUAL_REVENUE_DATA.items():\n",
        "    print(f\"  {company}: ${revenue:,.0f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR8RCvOzfsUl",
        "outputId": "0b03c936-3014-451d-8077-43e09d44df0b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Automation solution saved to automation_solution.json\n",
            "  Wincanton: $1,406,600,000\n",
            "  Expeditors: $10,600,000,000\n",
            "  Black Sheep UK: $50,000,000\n",
            "  Davies Turner: $150,000,000\n",
            "  Edrington: $800,000,000\n",
            "  Bahrain Post: $25,000,000\n",
            "  Kuwait Post: $30,000,000\n",
            "  Jotun Paints GCC: $200,000,000\n",
            "  MAF: $15,000,000,000\n",
            "  Gulftainer: $500,000,000\n"
          ]
        }
      ]
    }
  ]
}